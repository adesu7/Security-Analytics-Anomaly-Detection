{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "le = LabelEncoder()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data from A2_2\n",
    "\n",
    "task1_data_dir = '/Users/adityadesu/Desktop/COMP90073/Assignment - 2/A2_2'\n",
    "rootpath2 = '/Users/adityadesu/Desktop/COMP90073/Assignement - 2 Report/'\n",
    "\n",
    "#Load training data\n",
    "train_data = pd.read_csv(os.path.join(task1_data_dir, '2_training_data_with_label.csv'))\n",
    "\n",
    "# Load validation data\n",
    "val_data = pd.read_csv(os.path.join(task1_data_dir, '2_validation_data_with_label.csv'))\n",
    "\n",
    "# Load test data\n",
    "test_data = pd.read_csv(os.path.join(task1_data_dir, '2_test_data_with_label.csv'))\n",
    "\n",
    "# Add a column names to all the dataframes\n",
    "features = ['stream_ID','date-time', 'duration','protocol', 'src_ip', 'src_port', 'direction', 'dst_ip', 'dst_port', 'state', 'src_type', 'dst_type','total_packets', 'two-way-byte_transf', 'src-dst-byte-transf', 'label']\n",
    "train_data.columns = features\n",
    "val_data.columns = features\n",
    "test_data.columns = features\n",
    "\n",
    "# Convert anomaly to 1 and normal to 0\n",
    "train_data.loc[train_data['label'].str.contains('Botnet'), 'label'] = 1\n",
    "train_data.loc[train_data['label'].str.contains('Botnet')==False, 'label'] = 0\n",
    "\n",
    "val_data.loc[val_data['label'].str.contains('Botnet'), 'label'] = 1\n",
    "val_data.loc[val_data['label'].str.contains('Botnet')==False, 'label'] = 0\n",
    "\n",
    "test_data.loc[test_data['label'].str.contains('Botnet'), 'label'] = 1\n",
    "test_data.loc[test_data['label'].str.contains('Botnet')==False, 'label'] = 0\n",
    "\n",
    "# Save labels of data\n",
    "train_labels = train_data['label'].values\n",
    "val_labels = val_data['label'].values\n",
    "test_labels = test_data['label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count no of labels contianing botnet\n",
    "train_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of instances with null values\n",
    "#print(\"Count of training instances with missing values:\\n\",train_data.isnull().sum())\n",
    "#print(\"Count of training instances with missing values:\\n\",val_data.isnull().sum())\n",
    "#print(\"Count of training instances with missing values:\\n\",test_data.isnull().sum())\n",
    "\n",
    "# Fill missing values with mode\n",
    "train_data['state'].fillna(train_data['state'].mode()[0], inplace=True)\n",
    "train_data['src_type'].fillna(train_data['src_type'].mode()[0], inplace=True)\n",
    "train_data['dst_type'].fillna(train_data['dst_type'].mode()[0], inplace=True)\n",
    "\n",
    "# Fill missing values with mode\n",
    "val_data['state'].fillna(val_data['state'].mode()[0], inplace=True)\n",
    "val_data['src_type'].fillna(val_data['src_type'].mode()[0], inplace=True)\n",
    "val_data['dst_type'].fillna(val_data['dst_type'].mode()[0], inplace=True)\n",
    "\n",
    "\n",
    "# Fill missing values with mode\n",
    "test_data['state'].fillna(test_data['state'].mode()[0], inplace=True)\n",
    "test_data['src_type'].fillna(test_data['src_type'].mode()[0], inplace=True)\n",
    "test_data['dst_type'].fillna(test_data['dst_type'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data['label'].value_counts())\n",
    "print(val_data['label'].value_counts())\n",
    "print(test_data['label'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_generator(df):\n",
    "    ''' Generate features from the data\n",
    "    params:\n",
    "        df: dataframe\n",
    "    returns:\n",
    "        df: dataframe with new features'''\n",
    "    # Join src ip, dst ip and dst port\n",
    "    #df['irc'] = df['src_ip'].str.cat(df['dst_ip'], sep=\"\").str.cat(df['dst_port'].astype(str), sep=\"\")\n",
    "    feature_generated_df = pd.DataFrame()\n",
    "    #Compute difference between alternate date-time values\n",
    "    feature_generated_df['duration'] = df['duration']\n",
    "    feature_generated_df['src_ip'] = df['src_ip']\n",
    "    feature_generated_df['total_packets'] = df['total_packets']\n",
    "    #feature_generated_df['dst_ip'] = le.fit_transform(df['dst_ip'])\n",
    "    feature_generated_df['pps'] = df['total_packets']/df['duration'].replace({0:np.inf})\n",
    "    feature_generated_df['bps'] = df['two-way-byte_transf']/df['duration'].replace({0:np.inf})\n",
    "    feature_generated_df['bps_src'] = df['src-dst-byte-transf']/df['duration'].replace({0:np.inf})\n",
    "    feature_generated_df['bps_two-way'] = df['two-way-byte_transf']/df['duration'].replace({0:np.inf})\n",
    "    feature_generated_df['bytes_per_packet'] = df['two-way-byte_transf']/df['total_packets'].replace({0:np.inf})\n",
    "    feature_generated_df['bytes_per_packet_src'] = df['src-dst-byte-transf']/df['total_packets'].replace({0:np.inf})\n",
    "    feature_generated_df['label'] = df['label']\n",
    "    return feature_generated_df\n",
    "\n",
    "# Generate features\n",
    "feature_generated_training_data = feature_generator(train_data)\n",
    "feature_generated_val_data = feature_generator(val_data)\n",
    "feature_generated_test_data = feature_generator(test_data)\n",
    "\n",
    "feature_generated_training_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bot_ips = train_data[train_data['label']==1]['src_ip'].unique()\n",
    "val_bot_ips = val_data[val_data['label']==1]['src_ip'].unique()\n",
    "test_bot_ips = test_data[test_data['label']==1]['src_ip'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_generated_training_data('label').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_generated_training_data.groupby('label')['src_ip'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract for each IP address: (1) mean outbound packet size, (2) variance of outbound packet size, (3) mean packet count per second, (4) max packet count per second, (5) mean of packet jitter, (6) variance of packet jitter.\n",
    "\n",
    "def extract_features_ip(df):\n",
    "    ''' Extract features from the data\n",
    "    params:\n",
    "        df: dataframe\n",
    "    returns:\n",
    "        df: dataframe with new features'''\n",
    "        \n",
    "    df2 = df.groupby('src_ip').agg({'total_packets': ['mean', 'var'], 'pps': ['mean', 'max'], 'duration': ['mean', 'var'], 'bps': ['mean', 'var'], 'bps_src': ['mean', 'var'], 'bps_two-way': ['mean', 'var'], 'bytes_per_packet': ['mean', 'var']})\n",
    "    # flatten the column names\n",
    "    df2.columns = ['_'.join(col).strip() for col in df2.columns.values]\n",
    "    # reset index\n",
    "    df2 = df2.reset_index()\n",
    "    # rename columns\n",
    "    df2.columns = ['src_ip','mean_otb_pkt_size', 'var_otb_pkt_size','mean_pkt_cnt_per_sec', 'max_pkt_cnt_per_sec', 'mean_pkt_jitter', 'var_pkt_jitter', 'mean_bps', 'var_bps', 'mean_bps_src', 'var_bps_src', 'mean_bps_two_way', 'var_bps_two_way', 'mean_bytes_per_pkt', 'var_bytes_per_pkt']\n",
    "\n",
    "    # add label column\n",
    "    \n",
    "\n",
    "    return df2\n",
    "\n",
    "feature_generated_training_data = extract_features_ip(feature_generated_training_data)\n",
    "feature_generated_val_data = extract_features_ip(feature_generated_val_data)\n",
    "feature_generated_test_data = extract_features_ip(feature_generated_test_data)\n",
    "\n",
    "\n",
    "# Replace all Nan values with 0\n",
    "feature_generated_training_data.fillna(0, inplace=True)\n",
    "feature_generated_val_data.fillna(0, inplace=True)\n",
    "feature_generated_test_data.fillna(0, inplace=True)\n",
    "\n",
    "# Add label column by normal or botnet label\n",
    "feature_generated_training_data['label'] = feature_generated_training_data['src_ip'].apply(lambda x: 1 if x in train_bot_ips else 0)\n",
    "feature_generated_val_data['label'] = feature_generated_val_data['src_ip'].apply(lambda x: 1 if x in val_bot_ips else 0)\n",
    "feature_generated_test_data['label'] = feature_generated_test_data['src_ip'].apply(lambda x: 1 if x in test_bot_ips else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_generated_test_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "feature_generated_training_data.to_csv('training_data_agg.csv', index=False)\n",
    "feature_generated_val_data.to_csv('val_data_agg.csv', index=False)\n",
    "feature_generated_test_data.to_csv('test_data_agg.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notebook can be run from here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "feature_generated_training_data = pd.read_csv('training_data_agg.csv')\n",
    "feature_generated_val_data = pd.read_csv('val_data_agg.csv')\n",
    "feature_generated_test_data = pd.read_csv('test_data_agg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    feature_generated_training_data.drop(['src_ip'], axis=1, inplace=True)\n",
    "    feature_generated_val_data.drop(['src_ip'], axis=1, inplace=True)\n",
    "    feature_generated_test_data.drop(['src_ip'], axis=1, inplace=True)\n",
    "\n",
    "except:\n",
    "    pass\n",
    "print(feature_generated_training_data.columns)\n",
    "\n",
    "feature_generated_val_data.iloc[:,0:14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#apply SelectKBest class to extract top 6 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=6)\n",
    "fit = bestfeatures.fit(feature_generated_training_data.iloc[:,0:14],feature_generated_training_data['label'].astype(int))\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(feature_generated_training_data.iloc[:,0:14].columns)\n",
    "\n",
    "#concat two dataframes for better visualization\n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "\n",
    "# print 4 best features\n",
    "print(featureScores.nlargest(6,'Score'))\n",
    "\n",
    "# Save best 4 features\n",
    "best_features = featureScores.nlargest(6,'Score')['Specs'].values\n",
    "\n",
    "# add label to the best features\n",
    "best_features = np.append(best_features, 'label')\n",
    "\n",
    "# Apply these features to the data\n",
    "feature_generated_training_data = feature_generated_training_data[best_features]\n",
    "feature_generated_val_data = feature_generated_val_data[best_features]\n",
    "feature_generated_test_data = feature_generated_test_data[best_features]\n",
    "\n",
    "#\n",
    "feature_generated_training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Standardisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply min max scaling\n",
    "\n",
    "scaler = StandardScaler()\n",
    "feature_generated_training_data.iloc[:,0:6] = scaler.fit_transform(feature_generated_training_data.iloc[:,0:6])\n",
    "feature_generated_training_data.head()\n",
    "feature_generated_val_data.iloc[:,0:6] = scaler.transform(feature_generated_val_data.iloc[:,0:6])\n",
    "feature_generated_test_data.iloc[:,0:6] = scaler.transform(feature_generated_test_data.iloc[:,0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accurate_outlier_preds(preds,labels):\n",
    "    ''' Calaculate the number of accurate outlier predictions\n",
    "        params:\n",
    "            preds: predictions\n",
    "            train_labels: true labels\n",
    "        returns:\n",
    "            number of accurate outlier predictions'''\n",
    "    accurate_outlier_count = 0\n",
    "    for i in range(len(preds)):\n",
    "        if preds[i] == 1:\n",
    "            if labels[i] == 1:\n",
    "                accurate_outlier_count +=1\n",
    "    return accurate_outlier_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create logistic regression\n",
    "logisticRegr = LogisticRegression(random_state = 0)\n",
    "\n",
    "# Train the classifier\n",
    "logisticRegr.fit(feature_generated_training_data.iloc[:,0:6], feature_generated_training_data['label'].astype(int))\n",
    "\n",
    "# Predict on training set\n",
    "pred = logisticRegr.predict(feature_generated_training_data.iloc[:,0:6])\n",
    "\n",
    "# View accuracy score\n",
    "print(\"Accuracy score (training): {0:.3f}\".format(accuracy_score(feature_generated_training_data['label'].astype(int), pred)))\n",
    "\n",
    "# View confusion matrix\n",
    "print(\"Confusion matrix (training):\")\n",
    "print(confusion_matrix(feature_generated_training_data['label'].astype(int), pred))\n",
    "\n",
    "# View classification report\n",
    "print(\"Classification report (training):\")\n",
    "print(classification_report(feature_generated_training_data['label'].astype(int), pred))\n",
    "\n",
    "a = accurate_outlier_preds(pred,feature_generated_training_data['label'].astype(int))\n",
    "print(\"Number of accurate outlier predictions (training):\",a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on validation set\n",
    "val_pred = logisticRegr.predict(feature_generated_val_data.iloc[:,0:6])\n",
    "\n",
    "# View accuracy score\n",
    "print(\"Accuracy score (validation): {0:.3f}\".format(accuracy_score(feature_generated_val_data['label'].astype(int), val_pred)))\n",
    "\n",
    "# View confusion matrix\n",
    "print(\"Confusion matrix (validation):\")\n",
    "print(confusion_matrix(feature_generated_val_data['label'].astype(int), val_pred))\n",
    "\n",
    "# View classification report\n",
    "print(\"Classification report (validation):\")\n",
    "print(classification_report(feature_generated_val_data['label'].astype(int), val_pred))\n",
    "\n",
    "a = accurate_outlier_preds(val_pred,feature_generated_val_data['label'].astype(int))\n",
    "print(\"Number of accurate outlier predictions (validation):\",a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "test_pred = logisticRegr.predict(feature_generated_test_data.iloc[:,0:6])\n",
    "\n",
    "# View accuracy score\n",
    "print(\"Accuracy score (test): {0:.3f}\".format(accuracy_score(feature_generated_test_data['label'].astype(int), test_pred)))\n",
    "\n",
    "# View confusion matrix\n",
    "print(\"Confusion matrix (test):\")\n",
    "print(confusion_matrix(feature_generated_test_data['label'].astype(int), test_pred))\n",
    "\n",
    "# View classification report\n",
    "print(\"Classification report (test):\")\n",
    "print(classification_report(feature_generated_test_data['label'].astype(int), test_pred))\n",
    "\n",
    "a = accurate_outlier_preds(test_pred,feature_generated_test_data['label'].astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and Testing on Oversampled botnet class data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample minority class using random oversampling\n",
    "\n",
    "ros = RandomOverSampler(sampling_strategy ='minority',random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(feature_generated_training_data.iloc[:,0:6], feature_generated_training_data['label'].astype(int))\n",
    "\n",
    "print(\"Number of samples in each class (training):\")\n",
    "print(y_resampled.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create logistic regression\n",
    "logisticRegr = LogisticRegression(random_state = 0)\n",
    "\n",
    "# Train the model\n",
    "logisticRegr.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predict on training set\n",
    "pred = logisticRegr.predict(X_resampled)\n",
    "\n",
    "# View accuracy score\n",
    "print(\"Accuracy score (training): {0:.3f}\".format(accuracy_score(y_resampled, pred)))\n",
    "\n",
    "# View confusion matrix\n",
    "print(\"Confusion matrix (training):\")\n",
    "print(confusion_matrix(y_resampled, pred))\n",
    "\n",
    "# View classification report\n",
    "print(\"Classification report (training):\")\n",
    "print(classification_report(y_resampled, pred))\n",
    "\n",
    "a = accurate_outlier_preds(pred,y_resampled)\n",
    "print(\"Number of accurate outlier predictions (training):\",a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on validation set\n",
    "val_pred = logisticRegr.predict(feature_generated_val_data.iloc[:,0:6])\n",
    "\n",
    "# View accuracy score\n",
    "print(\"Accuracy score (validation): {0:.3f}\".format(accuracy_score(feature_generated_val_data['label'].astype(int), val_pred)))\n",
    "\n",
    "# View confusion matrix\n",
    "print(\"Confusion matrix (validation):\")\n",
    "print(confusion_matrix(feature_generated_val_data['label'].astype(int), val_pred))\n",
    "\n",
    "# View classification report\n",
    "print(\"Classification report (validation):\")\n",
    "print(classification_report(feature_generated_val_data['label'].astype(int), val_pred))\n",
    "\n",
    "a = accurate_outlier_preds(val_pred,feature_generated_val_data['label'].astype(int))\n",
    "print(\"Number of accurate outlier predictions (validation):\",a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "test_pred = logisticRegr.predict(feature_generated_test_data.iloc[:,0:6])\n",
    "\n",
    "# View accuracy score\n",
    "print(\"Accuracy score (test): {0:.3f}\".format(accuracy_score(feature_generated_test_data['label'].astype(int), test_pred)))\n",
    "\n",
    "# View confusion matrix\n",
    "print(\"Confusion matrix (test):\")\n",
    "print(confusion_matrix(feature_generated_test_data['label'].astype(int), test_pred))\n",
    "\n",
    "# View classification report\n",
    "print(\"Classification report (test):\")\n",
    "print(classification_report(feature_generated_test_data['label'].astype(int), test_pred))\n",
    "\n",
    "a = accurate_outlier_preds(test_pred,feature_generated_test_data['label'].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c8ff9150cc796902298ec52b5115e0f1f4f1773b1f4c5ddde98975e31aced34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
